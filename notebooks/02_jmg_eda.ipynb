{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "Some preliminary questions we would like to address with the grant data we previously downloaded:\n",
    "\n",
    "* What are the levels of funding for health innovation (as defined in the project) in the UK\n",
    "* How has funding evolved over time?\n",
    "* What's its geography?\n",
    "* Who is supporting health innovation?\n",
    "* What are its topics?\n",
    "* What are example projects?\n",
    "* What is Nesta doing?\n",
    "\n",
    "We will at some point seek to compare the analysis of this funding landscape with the situation in the USA based on an analysis of the activities of RWJF.\n",
    "\n",
    "\n",
    "The main goals is to identify and explore health innovation related projects. This definition has a domain aspect (the projects need to seek improvements in health outcomes) and a novelty aspect (they need to be new or different from what's done in the field). We will explore several strategies to get a handle on this. This includes:\n",
    "\n",
    "1. Identify health projects\n",
    "\n",
    "We will use data about project categories (which are available for some if not all projects) to train a model predicting if it is in health, and also to analyse the overlaps between projects in health and other domains.\n",
    "\n",
    "2. Map activity inside health\n",
    "\n",
    "Once we have a corpus of 'health' projects, we will classify them into finer categories using a third party taxonomy (eg disease areas and project types).\n",
    "\n",
    "3. Find innovative projects\n",
    "\n",
    "This is the least straightforward part. We are looking for novelty. This can be defined in different ways:\n",
    "\n",
    "* Projects that mention innovation\n",
    "\n",
    "* Projects involving innovative technologies (in this case would look for keywords based on some domain-based list of technologies or keywords.\n",
    "\n",
    "* Projects similar to those sponsored by innovative organisations. Eg. Train a model on the Nesta data and look for similar projects\n",
    "\n",
    "* Projects that bridge domains in unusual ways\n",
    "\n",
    "* Projects that are unique in that they don't fall in existing clusters or form their own clusters (need to decide how to do the clustering).\n",
    "\n",
    "* Projects with trending keywords (keywords that started appearing recently in the data)\n",
    "\n",
    "\n",
    "...We will explore some of these options in the 360g data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#NB I open a standard set of directories\n",
    "\n",
    "#Paths\n",
    "\n",
    "#Get the top path\n",
    "top_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "#Create the path for external data\n",
    "ext_data = os.path.join(top_path,'data/external')\n",
    "\n",
    "#Raw path (for html downloads)\n",
    "\n",
    "raw_data = os.path.join(top_path,'data/raw')\n",
    "\n",
    "#And external data\n",
    "proc_data = os.path.join(top_path,'data/processed')\n",
    "\n",
    "fig_path = os.path.join(top_path,'reports/figures')\n",
    "\n",
    "#Get date for saving files\n",
    "today = datetime.datetime.today()\n",
    "\n",
    "today_str = \"_\".join([str(x) for x in [today.day,today.month,today.year]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Additional imports\n",
    "\n",
    "import ratelim\n",
    "\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ext_data+'/22_3_2018_file_download.p','rb') as infile:\n",
    "    t60_container = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial exploration\n",
    "\n",
    "We have a collection of dataframes from different sources. They don't always share fields.\n",
    "We need to determine the right set of fields to focus on for the rest of the analysis. We'll do that here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This list contains the dfs we have managed to download\n",
    "t60_dfs = [x for x in t60_container if type(x)==pd.core.frame.DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currency', 'description', 'title'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What columns are shared across datasets?\n",
    "t60_columns = [set([c.lower() for c in x.columns]) for x in t60_dfs]\n",
    "\n",
    "#This gives the intersection of all the sets\n",
    "u = set.intersection(*t60_columns)\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3 fields are shared. We will look for the columns which appear most often in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now let's see what fields appear most frequently\n",
    "\n",
    "def flatten_list(my_list):\n",
    "    '''\n",
    "    Turns a nested list into a flat list\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    flat = [x for el in my_list for x in el]\n",
    "    \n",
    "    return(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currency                           86\n",
       "title                              86\n",
       "description                        86\n",
       "award date                         82\n",
       "identifier                         82\n",
       "amount awarded                     82\n",
       "funding org:identifier             76\n",
       "funding org:name                   75\n",
       "recipient org:name                 75\n",
       "recipient org:identifier           75\n",
       "last modified                      69\n",
       "recipient org:charity number       67\n",
       "planned dates:duration (months)    53\n",
       "recipient org:company number       50\n",
       "grant programme:title              48\n",
       "planned dates:start date           47\n",
       "planned dates:end date             46\n",
       "beneficiary location:name          44\n",
       "recipient org:postal code          41\n",
       "recipient org:city                 40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This list comprehension gives us a list of column names for each df (we lower them)\n",
    "t60_column_names = [[name.lower() for name in x.columns] for x in t60_dfs]\n",
    "\n",
    "#And here are their frequencies - remember we \n",
    "column_freq = pd.Series(flatten_list(t60_column_names)).value_counts()\n",
    "\n",
    "column_freq[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's see what's the coverage with different shared column names.\n",
    "\n",
    "def extract_shared_variables(variable_names,df_list):\n",
    "    '''\n",
    "    Takes a list of fields and returns a concatenated df with them.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df_container = []\n",
    "    \n",
    "    for x in df_list:\n",
    "        x.columns = [f.lower() for f in x.columns]\n",
    "        \n",
    "        x_subset = x[[var for var in x.columns if var in variable_names]]\n",
    "        df_container.append(x_subset)\n",
    "        \n",
    "    df_concat = pd.concat(df_container,axis=0)\n",
    "    \n",
    "    return(df_concat)\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#And here is the shared df!\n",
    "t60_df = extract_shared_variables(column_freq[:20].index,t60_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount awarded',\n",
       " 'award date',\n",
       " 'currency',\n",
       " 'description',\n",
       " 'funding org:identifier',\n",
       " 'funding org:name',\n",
       " 'identifier',\n",
       " 'recipient org:identifier',\n",
       " 'recipient org:name',\n",
       " 'title']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many missing values per variable?\n",
    "\n",
    "#This list comprehension loops over the columns and gives us the columns above a certain threshold\n",
    "fields_above_thres = [val[0] for val in [(col,100*np.sum(t60_df[col].isna())/len(t60_df)) for col in t60_df.columns] if\n",
    "                      val[1]<10]\n",
    "\n",
    "fields_above_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the variables present in at least 10% of projects in the data. They contain a lost of the info\n",
    "we want to answer the questions above, with the exception of place :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_df = t60_df[fields_above_thres]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify health projects\n",
    "\n",
    "We have attempted multiple strategies to identify health projects. Some things that didn't work:\n",
    "\n",
    "* Look for a labelled dataset with 'health labels'. There are only a few datasets in the 360d data with such labels, but their descriptions seem too short to be able to train a model predicting words associated to labels.\n",
    "\n",
    "* Look for a vocabulary of health-related words in those projects that are labelled as 'health'. Perhaps unsurprisingly given the above, we find that most of the project descriptions are insufficiently descriptive to do this.\n",
    "\n",
    "So we have used a crude approach instead: look for projects that mention health or similar terms identified through a word embedding analysis of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import string as stri\n",
    "\n",
    "stop = stopwords.words('English')\n",
    "\n",
    "#We want to keep the hyphen\n",
    "punct = r'['+\"\".join([x for x in stri.punctuation if x!='-'])+']'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t60h = extract_shared_variables(fields_above_thres,t60_dfs).reset_index(drop=True)\n",
    "\n",
    "t60h.columns = ['value','award_date','currency','description','funder_id','funder_name','identifier',\n",
    "                'recipient_id','recipient_name','title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tokenise descriptions and remove stopwords\n",
    "\n",
    "#Levels of this list comprehension: descriptions -> words in the description if words not in stopword list after\n",
    "#removing punctuation\n",
    "#and np.nan if the description is a number\n",
    "\n",
    "t60h['description_tokens'] = [\n",
    "    [[w.lower().strip() for w in re.sub(punct,' ',x).split(\" \") if w.lower() not in set(stop+[''])] if type(x)==str else np.nan][0] for x in t60h.description]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start an exploration of the tokens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When calculating the word frequencies we want to ignore the elements in the list which are na\n",
    "word_freq = pd.Series(flatten_list(t60h.description_tokens.dropna())).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     65769.000000\n",
       "mean         85.793809\n",
       "std        1318.853684\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           6.000000\n",
       "max      140091.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As usual, very skewed distribution\n",
    "\n",
    "word_freq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project       140091\n",
       "funding       105082\n",
       "group          87747\n",
       "community      86970\n",
       "people         79764\n",
       "use            69683\n",
       "grant          60921\n",
       "provide        55926\n",
       "activities     49879\n",
       "costs          44968\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the words that tend to appear are not super surprising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok - so we train a word 2 vec model in lour corpus using the default parameters\n",
    "\n",
    "w2v = gensim.models.Word2Vec(t60h['description_tokens'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['independence',\n",
       " 'well-being',\n",
       " 'outcomes',\n",
       " 'distress',\n",
       " 'ill-health',\n",
       " 'illness',\n",
       " 'well',\n",
       " 'diet',\n",
       " 'self-esteem',\n",
       " 'fitness',\n",
       " 'ill',\n",
       " 'overall',\n",
       " 'resilience',\n",
       " 'conditions',\n",
       " 'health',\n",
       " 'wellbeing']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get the most similar words to health\n",
    "#We need a bit more pre-processing in the data\n",
    "\n",
    "health_words = list(\n",
    "    set(flatten_list([[x[0] for x in w2v.most_similar(w) if x[1]>0.5] for w in ['health','wellbeing']])))+['health',\n",
    "                                                                                                          'wellbeing']\n",
    "\n",
    "#These are the top health words\n",
    "health_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab', 'innovation']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "innovation_words = list(\n",
    "    set(flatten_list([[x[0] for x in w2v.most_similar(w) if x[1]>0.7] for w in ['innovation']])))+['innovation']\n",
    "\n",
    "innovation_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list comprehension returns the number of times a health-related word appears in a description\n",
    "t60h['health_terms_n'] = [np.sum(\n",
    "    [x in dt for x in health_words]) if type(dt)==list else np.nan for dt in t60h['description_tokens']]\n",
    "\n",
    "t60h['innovation_terms_n'] = [np.sum(\n",
    "    [x in dt for x in innovation_words]) if type(dt)==list else np.nan for dt in t60h['description_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_innovation_projects = t60h.loc[(t60h.health_terms_n>0) & \n",
    "                           (t60h.innovation_terms_n>0),:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 13)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_innovation_projects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at Nesta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the Nesta data\n",
    "\n",
    "def get_360_file(url):\n",
    "    '''\n",
    "    This function downloads each file in the 360 degree data. We mostly create it to decorate with the rate limiter,\n",
    "    which slows down the pace at which we download files from 360.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Different data sources have different formatrs so we have to work with that as well.\n",
    "    \n",
    "    #Get the file\n",
    "    request = requests.get(url)\n",
    "    \n",
    "    #If the status code is 200, parse etc.\n",
    "    if request.status_code==200:\n",
    "        \n",
    "            file_type_string = get_file_type_string(request)\n",
    "        \n",
    "        #The parsing depends on the type of file. We get the type of file from the header or the url name\n",
    "        \n",
    "            #This takes ages with large files.\n",
    "            if '.csv' in file_type_string:\n",
    "                #We need to stream the text into the csv\n",
    "                table = pd.read_csv(io.StringIO(request.text))\n",
    "            \n",
    "            elif '.xls' in file_type_string:\n",
    "                #Excel is a bit different\n",
    "                with io.BytesIO(request.content) as fh:\n",
    "                    table = pd.io.excel.read_excel(fh, sheetname=0)\n",
    "\n",
    "            elif '.json' in file_type_string:\n",
    "                #There is even one download with json!\n",
    "                table = pd.DataFrame.from_dict(request.json()['grants'])\n",
    "\n",
    "            return(table)\n",
    "    \n",
    "    else:\n",
    "        #error = requests.get(url).error\n",
    "        return(request.status_code)\n",
    "    \n",
    "    \n",
    "def get_file_type_string(request):\n",
    "    '''\n",
    "    This function takes the return from a webpage objec and returns a string where we look for the file type\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Extract the url. This will often contain the file extension\n",
    "    text = request.url\n",
    "    \n",
    "    #Also add metadata from the get, in case there was no file extension:\n",
    "    if 'Content-Disposition' in request.headers:\n",
    "        text = text + ' '+request.headers['Content-Disposition']\n",
    "        \n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesta = get_360_file('http://www.nesta.org.uk/sites/default/files/360giving_data_export_12.05.17.csv')\n",
    "\n",
    "nesta_hl = nesta.loc[nesta['Funding Org:Department']=='Health Lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipient Org:Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Encore Futures Limited</td>\n",
       "      <td>Ageing programme grant to Encore Futures Limit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Glasgow Caledonian University</td>\n",
       "      <td>Dementia Citizens programme grant to Glasgow C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Book of You CIC</td>\n",
       "      <td>Dementia Citizens programme grant to Book of Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Stroke Association</td>\n",
       "      <td>Accelerating Ideas programme grant to The Stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The British Red Cross Society</td>\n",
       "      <td>Accelerating Ideas programme grant to The Brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Turning Point</td>\n",
       "      <td>People Powered Health programme grant to Turni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Lambeth Primary Care Trust</td>\n",
       "      <td>People Powered Health programme grant to Lambe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Calderdale and Huddersfield NHS Foundation Trust</td>\n",
       "      <td>People Powered Health programme grant to Calde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Newcastle Bridges Commissioning Consortium</td>\n",
       "      <td>People Powered Health programme grant to Newca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Newcastle Bridges Commissioning Consortium</td>\n",
       "      <td>People Powered Health programme grant to Newca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Stockport Metropolitan Borough Council</td>\n",
       "      <td>People Powered Health programme grant to Stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Leeds Community Healthcare NHS Trust</td>\n",
       "      <td>People Powered Health programme grant to Leeds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Sheffield Teaching Hospitals NHS Foundation Trust</td>\n",
       "      <td>Helping in Hospitals programme grant to Sheffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Kingston Hospital NHS Foundation Trust</td>\n",
       "      <td>Helping in Hospitals programme grant to Kingst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Cambridge University Hospital NHS Foundation T...</td>\n",
       "      <td>Helping in Hospitals programme grant to Cambri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Derbyshire Community Health Services</td>\n",
       "      <td>Helping in Hospitals programme grant to Derbys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Great Western Hospitals NHS Foundation Trust</td>\n",
       "      <td>Helping in Hospitals programme grant to Great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Barts Health NHS Trust</td>\n",
       "      <td>Helping in Hospitals programme grant to Barts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>University Hospital Southampton NHS Trust</td>\n",
       "      <td>Young People Helping in Hospitals programme gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Royal Free London NHS Foundation Trust</td>\n",
       "      <td>Young People Helping in Hospitals programme gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Western Sussex Hospitals NHS Foundation Trust</td>\n",
       "      <td>Young People Helping in Hospitals programme gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Princess Alexandra Hospital NHS trust</td>\n",
       "      <td>Young People Helping in Hospitals programme gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>The Stroke Association</td>\n",
       "      <td>Accelerating Ideas programme grant to The Stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>The British Red Cross Society</td>\n",
       "      <td>Accelerating Ideas programme grant to The Brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Carers UK</td>\n",
       "      <td>Accelerating Ideas programme grant to Carers U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Shared Lives Plus Limited</td>\n",
       "      <td>Accelerating Ideas programme grant to Shared L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>British Lung Foundation</td>\n",
       "      <td>Accelerating Ideas programme grant to British ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Diabetes UK</td>\n",
       "      <td>Accelerating Ideas programme grant to Diabetes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Positively UK</td>\n",
       "      <td>Realising the Value programme grant to Positiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Unlimited Potential</td>\n",
       "      <td>Realising the Value programme grant to Unlimit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>The Health Foundation</td>\n",
       "      <td>Realising the Value programme grant to The Hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Newcastle University</td>\n",
       "      <td>Realising the Value programme grant to Newcast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>GoodSAM</td>\n",
       "      <td>Accelerating Ideas programme grant to GoodSAM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Bedfordshire Rural Communities Charity</td>\n",
       "      <td>Accelerating Ideas programme grant to Bedfords...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>NL Cares (T/A North London Cares)</td>\n",
       "      <td>Accelerating Ideas programme grant to NL Cares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>The Good Gym</td>\n",
       "      <td>Accelerating Ideas programme grant to The Good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>The Conservation Volunteers</td>\n",
       "      <td>Accelerating Ideas programme grant to The Cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>National Voices</td>\n",
       "      <td>Realising the Value programme grant to Nationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Penny Brohn Cancer Care</td>\n",
       "      <td>Realising the Value programme grant to Penny B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Big Life Centres</td>\n",
       "      <td>Realising the Value programme grant to Big Lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>South West Yorkshire Partnerships NHS Foundati...</td>\n",
       "      <td>Realising the Value programme grant to South W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Carers UK</td>\n",
       "      <td>Accelerating Ideas programme grant to Carers U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>The Good Gym</td>\n",
       "      <td>Accelerating Ideas programme grant to The Good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>NL Cares (T/A North London Cares)</td>\n",
       "      <td>Accelerating Ideas programme grant to NL Cares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>GoodSAM</td>\n",
       "      <td>Accelerating Ideas programme grant to GoodSAM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>British Lung Foundation</td>\n",
       "      <td>Accelerating Ideas programme grant to British ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Shared Lives Plus Limited</td>\n",
       "      <td>Accelerating Ideas programme grant to Shared L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Recipient Org:Name  \\\n",
       "38                              Encore Futures Limited   \n",
       "42                       Glasgow Caledonian University   \n",
       "44                                     Book of You CIC   \n",
       "45                              The Stroke Association   \n",
       "46                       The British Red Cross Society   \n",
       "117                                      Turning Point   \n",
       "118                         Lambeth Primary Care Trust   \n",
       "119   Calderdale and Huddersfield NHS Foundation Trust   \n",
       "120         Newcastle Bridges Commissioning Consortium   \n",
       "121         Newcastle Bridges Commissioning Consortium   \n",
       "363             Stockport Metropolitan Borough Council   \n",
       "364               Leeds Community Healthcare NHS Trust   \n",
       "380  Sheffield Teaching Hospitals NHS Foundation Trust   \n",
       "381             Kingston Hospital NHS Foundation Trust   \n",
       "382  Cambridge University Hospital NHS Foundation T...   \n",
       "383               Derbyshire Community Health Services   \n",
       "384       Great Western Hospitals NHS Foundation Trust   \n",
       "385                             Barts Health NHS Trust   \n",
       "386          University Hospital Southampton NHS Trust   \n",
       "387             Royal Free London NHS Foundation Trust   \n",
       "389      Western Sussex Hospitals NHS Foundation Trust   \n",
       "390              Princess Alexandra Hospital NHS trust   \n",
       "479                             The Stroke Association   \n",
       "480                      The British Red Cross Society   \n",
       "481                                          Carers UK   \n",
       "482                          Shared Lives Plus Limited   \n",
       "483                            British Lung Foundation   \n",
       "484                                        Diabetes UK   \n",
       "496                                      Positively UK   \n",
       "497                                Unlimited Potential   \n",
       "505                              The Health Foundation   \n",
       "506                               Newcastle University   \n",
       "507                                            GoodSAM   \n",
       "508             Bedfordshire Rural Communities Charity   \n",
       "509                  NL Cares (T/A North London Cares)   \n",
       "510                                       The Good Gym   \n",
       "511                        The Conservation Volunteers   \n",
       "513                                    National Voices   \n",
       "514                            Penny Brohn Cancer Care   \n",
       "515                                   Big Life Centres   \n",
       "516  South West Yorkshire Partnerships NHS Foundati...   \n",
       "550                                          Carers UK   \n",
       "552                                       The Good Gym   \n",
       "553                  NL Cares (T/A North London Cares)   \n",
       "554                                            GoodSAM   \n",
       "555                            British Lung Foundation   \n",
       "556                          Shared Lives Plus Limited   \n",
       "\n",
       "                                           Description  \n",
       "38   Ageing programme grant to Encore Futures Limit...  \n",
       "42   Dementia Citizens programme grant to Glasgow C...  \n",
       "44   Dementia Citizens programme grant to Book of Y...  \n",
       "45   Accelerating Ideas programme grant to The Stro...  \n",
       "46   Accelerating Ideas programme grant to The Brit...  \n",
       "117  People Powered Health programme grant to Turni...  \n",
       "118  People Powered Health programme grant to Lambe...  \n",
       "119  People Powered Health programme grant to Calde...  \n",
       "120  People Powered Health programme grant to Newca...  \n",
       "121  People Powered Health programme grant to Newca...  \n",
       "363  People Powered Health programme grant to Stock...  \n",
       "364  People Powered Health programme grant to Leeds...  \n",
       "380  Helping in Hospitals programme grant to Sheffi...  \n",
       "381  Helping in Hospitals programme grant to Kingst...  \n",
       "382  Helping in Hospitals programme grant to Cambri...  \n",
       "383  Helping in Hospitals programme grant to Derbys...  \n",
       "384  Helping in Hospitals programme grant to Great ...  \n",
       "385  Helping in Hospitals programme grant to Barts ...  \n",
       "386  Young People Helping in Hospitals programme gr...  \n",
       "387  Young People Helping in Hospitals programme gr...  \n",
       "389  Young People Helping in Hospitals programme gr...  \n",
       "390  Young People Helping in Hospitals programme gr...  \n",
       "479  Accelerating Ideas programme grant to The Stro...  \n",
       "480  Accelerating Ideas programme grant to The Brit...  \n",
       "481  Accelerating Ideas programme grant to Carers U...  \n",
       "482  Accelerating Ideas programme grant to Shared L...  \n",
       "483  Accelerating Ideas programme grant to British ...  \n",
       "484  Accelerating Ideas programme grant to Diabetes...  \n",
       "496  Realising the Value programme grant to Positiv...  \n",
       "497  Realising the Value programme grant to Unlimit...  \n",
       "505  Realising the Value programme grant to The Hea...  \n",
       "506  Realising the Value programme grant to Newcast...  \n",
       "507  Accelerating Ideas programme grant to GoodSAM ...  \n",
       "508  Accelerating Ideas programme grant to Bedfords...  \n",
       "509  Accelerating Ideas programme grant to NL Cares...  \n",
       "510  Accelerating Ideas programme grant to The Good...  \n",
       "511  Accelerating Ideas programme grant to The Cons...  \n",
       "513  Realising the Value programme grant to Nationa...  \n",
       "514  Realising the Value programme grant to Penny B...  \n",
       "515  Realising the Value programme grant to Big Lif...  \n",
       "516  Realising the Value programme grant to South W...  \n",
       "550  Accelerating Ideas programme grant to Carers U...  \n",
       "552  Accelerating Ideas programme grant to The Good...  \n",
       "553  Accelerating Ideas programme grant to NL Cares...  \n",
       "554  Accelerating Ideas programme grant to GoodSAM ...  \n",
       "555  Accelerating Ideas programme grant to British ...  \n",
       "556  Accelerating Ideas programme grant to Shared L...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nesta_hl[['Recipient Org:Name','Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
